---
title: "week2"
author: "Hyungyeong Hong"
date: "9/13/2021"
output: html_document
---

# Chapter1. 모델링을 위한 데이터 전처리

## 문제 0. 기본 세팅
```{r}
source("0번.txt")
```

## 문제1. train 데이터 불러온 후 기본 구조 파악, 데이터 개수, 변수 개수, 데이터 형식 파악

```{r}
train <- fread("train.csv")
```

```{r}
str(train)
```

```{r}
train %>% summarise_all(n_distinct)
```

## 문제2. 각 데이터의 칼럼명 확인 및 칼럼명 변경
```{r}
train %>% colnames
```

```{r}
train  <- train %>% rename("지하철개수" = "도보 10분거리 내 지하철역 수(환승노선 수 반영)",
                 "버스개수" = "도보 10분거리 내 버스정류장 수")
```

```{r}
test <- fread("test.csv")
test %>% colnames
```

```{r}
test <- test %>% rename("지하철개수" = "도보 10분거리 내 지하철역 수(환승노선 수 반영)",
                 "버스개수" = "도보 10분거리 내 버스정류장 수")
```

## 문제3. '임대료', '임대보증금'이 문자로 되어 있는 이유를 찾아 수치형으로 변경
* NA 값이 "", 또는 "-"으로 표현되어 있음
* 위의 값들을 NA로 바꿔준 후 해당 칼럼들을 수치형으로 변경
```{r}
train %>% select(임대료) %>% apply(2, unique) %>% sort
```

```{r}
train %>% select(임대보증금) %>% apply(2, unique) %>% sort
```

```{r}
train_na <- which(train$임대료 == "" | train$임대료 == "-")
train$임대료[train_na] <- NA

train_na <- which(train$임대보증금 == "" | train$임대보증금 == "-")
train$임대보증금[train_na] <- NA

train$임대료 <- train$임대료 %>% as.numeric
train$임대보증금 <- train$임대보증금 %>% as.numeric
```

```{r}
test_na <- which(test$임대료 == "" | test$임대료 == "-")
test$임대료[test_na] <- NA

test_na <- which(test$임대보증금 == "" | test$임대보증금 == "-")
test$임대보증금[test_na] <- NA

test$임대료 <- test$임대료 %>% as.numeric
test$임대보증금 <- test$임대보증금 %>% as.numeric
```

## 문제4. 열별로 NA 개수 확인
```{r}
train_na_cnt <- apply(train, 2, is.na) %>% colSums %>% sort(decreasing = TRUE) %>% as.data.frame %>% rename("na_cnt" = ".")
train_na_cnt <- train_na_cnt %>% mutate(col_name = rownames(train_na_cnt))
```

```{r include=FALSE}
theme_set(theme_light(base_family='NanumGothic'))
```

```{r}
train_na_cnt %>% ggplot() +
  geom_bar(aes(x = reorder(col_name, na_cnt), y = na_cnt, fill = na_cnt, color = na_cnt),
           stat = "identity", alpha = 0.1, cex = 0.2) +
  geom_text(aes(x = reorder(col_name, na_cnt), y = na_cnt/2, label = na_cnt, color = na_cnt)) +
  coord_flip() +
  theme_set(theme_light(base_family='NanumGothic')) +
  scale_fill_gradient(high = "#B43C8A", low = "#81D8D0", guide = "colourbar", aesthetics = "fill", name = "NA개수") +
  scale_color_gradient(high = "#B43C8A", low = "#81D8D0", guide = "colourbar", aesthetics = "color", name = "NA개수") +
  ggtitle("컬럼별 NA 개수") +
  xlab("칼럼명") +
  ylab("NA개수")
```

## 문제 5. 범주형변수를 factor변수로, 정수형변수를 수치형으로 바꾸기

```{r}
train <- train %>% 
  mutate_if(is.integer, as.numeric) %>% 
  mutate_if(is.character, as.factor)
```

```{r}
test <- test %>% 
  mutate_if(is.integer, as.numeric) %>% 
  mutate_if(is.character, as.factor)
```


## 문제 6. NA 값을 mean imputation
```{r}
train <- train %>% as.data.frame

for(i in 1:ncol(train)){
  if(is.numeric(train[,i]) == FALSE){
    next
  } else {
    train[,i] <- replace(train[,i], is.na(train[,i]), mean(train[,i], na.rm = TRUE))
  }
}

train <- train %>% as.data.table
```

```{r}
test <- test %>% as.data.frame

for(i in 1:ncol(test)){
  if(is.numeric(test[,i]) == FALSE){
    next
  } else {
    test[,i] <- replace(test[,i], is.na(test[,i]), mean(test[,i], na.rm = TRUE))
  }
}

test <- test %>% as.data.table
```

## 문제 7. 공급유형 == "장기전세" 이면서 임대료 != 0 확인
```{r}
which(train$공급유형 == "장기전세" & train$임대료 != 0)
```

```{r}
test$임대료[which(test$공급유형 == "장기전세" & test$임대료 != 0)] <- 0
```

## 문제 8. 면적당 임대료, 면적당 임대보증금 계산하여 파생변수 생성
```{r}
train <- train %>% mutate(면적당임대료 = 임대료 / 전용면적, 면적당임대보증금 = 임대보증금 / 전용면적)
test <- test %>% mutate(면적당임대료 = 임대료 / 전용면적, 면적당임대보증금 = 임대보증금 / 전용면적)
```

## 문제 9. 임대료, 임대보증금, 단지코드 삭제
```{r}
train <- train %>% select(-c(임대료, 임대보증금, 단지코드))
test <- test %>% select(-c(임대료, 임대보증금, 단지코드))
```

# Chapter 2. 랜덤포레스트 및 교차검증

# Chapter 2-1: [Hold-Out]

## 문제 1. 데이터 층화추출을 사용하여 train:validation 7:3 split
```{r}
set.seed(2728)
train_idx <- createDataPartition(train$등록차량수, p = 0.7, list = FALSE)
train_set <- train[train_idx, ]
valid_set <- train[-train_idx, ]
```

## 문제 2. 랜덤포레스트의 하이퍼파라미터에 대한 설명
* 결정 트리의 개수(ntree): 트리 기반 모델인 랜덤포레스트에서 결정 트리의 개수를 지정하며, 값을 크게 설정할수록 좋은 성능 기대할 수 있지만 무조건적으로 증가시킨다고 항상 성능 향상이 이루어지지는 않는다. 결정 트리의 개수를 늘릴수록 학습 수행 시간이 오래걸린다.
* 트리 분할에 사용할 피처의 개수(mtry): 랜덤포레스트 트리 분할 시 참조할 피처의 개수이다. 즉, 매 모델링마다 사용되는 피처의 개수에 해당한다. 분류 문제의 경우 전체 피처 수의 제곱근만큼, 예측 문제의 경우 전체 피처 수의 1/3 미만을 선택하는 것이 경험적으로 좋은 선택지라고 알려져 있다.
* 이외에도 말단 노드의 최소 크기를 지정하는 nodesize, 말단 노드의 최대 개수를 지정하는 maxnodes가 있다.

## 문제 3. 그리드서치를 위한 데이터프레임 생성
```{r}
rf_params_HO <- expand.grid(mtry = c(5, 6, 7, 8),
                        ntree = c(200, 300, 400),
                        RMSE = NA)
rf_params_HO
```

## 문제 4. Random Forest 모델링
* for loop을 이용하여 등록차량수를 예측하는 랜덤포레스트 모델링 진행
* validation set의 RMSE를 계산하여 rf_params_HO에 값 넣어주기
```{r}
set.seed(2728)

for(i in 1:nrow(rf_params_HO)){
  rf_model <- randomForest(등록차량수~., train_set, 
                              mtry = rf_params_HO$mtry[i],
                              ntree = rf_params_HO$ntree[i])
  rf_yhat = predict(rf_model, newdata = valid_set)
  rf_params_HO$RMSE[i] <- RMSE(rf_yhat, valid_set$등록차량수)
}

rf_params_HO
```

## 문제 5. Hold-Out Random Forest 모델링 결과 시각화
* 해석: mtry가 8일 때는 트리의 개수가 늘어나면 RMSE 값이 줄어들어 성능이 향상된다고 볼 수 있겠으나, 나머지는 딱히.. 플랏을 보니 피처 개수가 늘어날수록 성능이 좋아지는 것 같지만 항상 그런 것은 아닌 듯 하다.. 트리 개수가 적을 때에는 오히려 많은 피처 개수가 해가 되는 것을 확인할 수 있겠다.
```{r}
rf_params_HO %>% ggplot(aes(x = mtry, y = ntree, fill = RMSE)) +
  geom_tile() +
  scale_fill_gradient(high = "#3CAEA3", low = "#D2F7F4", aesthetics = "fill",
                      breaks = c(74, 75, 76, 77)) +
  theme_set(theme_light(base_family='NanumGothic')) +
  ggtitle("Hold-out Method 결과")
```

## 문제 6. RMSE가 가장 낮은 하이퍼파라미터 조합을 출력
```{r}
rf_params_HO %>% filter(RMSE == min(RMSE))
```

# Chapter 2-2: [5-fold CV]

## 문제 7. 5-fold 교차검증을 위해 층화추출을 사용하여 CV 인덱스 생성
```{r}
set.seed(2728)
cv <- createFolds(train_set$등록차량수, k = 5)
```

## 문제 8. 그리드서치를 위한 데이터프레임 생성
```{r}
rf_params_KF <- expand.grid(mtry = c(5, 6, 7, 8),
                        ntree = c(200, 300, 400),
                        RMSE = NA)
rf_params_KF
```

## 문제 9. Random Forest 모델링
* 이중 for loop을 활용하여 등록차량수를 예측하는 랜덤포레스트 모델링 진행
* validation set의 RMSE를 계산하여 rf_params_KF에 값 넣어주기
```{r}
for (i in 1:nrow(rf_params_KF)){
  RMSE_tmp <- NULL
  
  for(j in 1:5){
    set.seed(2728)
    
    valid_idx <- cv[[j]]
    
    cv_train_set <- train[-valid_idx, ]
    cv_valid_set <- train[valid_idx, ]
    
    rf_model <- randomForest(등록차량수~., cv_train_set, 
                              mtry = rf_params_KF$mtry[i],
                              ntree = rf_params_KF$ntree[i])
    rf_yhat <- predict(rf_model, newdata = cv_valid_set)
    
    RMSE_tmp[j] <- RMSE(rf_yhat, cv_valid_set$등록차량수)
  }
  rf_params_KF$RMSE[i] <- mean(RMSE_tmp)
}

rf_params_KF
```

## 문제 10. 5-Out CV Random Forest 모델링 결과 시각화
* 해석: 참조하는 피처의 개수가 많이질수록 RMSE 값이 작은 것을 확인할 수 있다.
```{r}
rf_params_KF %>% ggplot(aes(x = mtry, y = ntree, fill = RMSE)) +
  geom_tile() +
  scale_fill_gradient(high = "#3CAEA3", low = "#D2F7F4", aesthetics = "fill") +
  theme_set(theme_light(base_family='NanumGothic')) +
  ggtitle("5-fold CV Method 결과")
```

## 문제 11. RMSE가 가장 낮은 하이퍼파라미터 조합을 출력
```{r}
rf_params_KF %>% filter(RMSE == min(RMSE))
```

# Chapter 2-3. 결과비교
## 문제 12. Hold-out 튜닝 결과와 5-fold CV 튜닝 결과 비교하여 시각화 및 해석
```{r}
rf_params_HO$method <- "Hold-out"
rf_params_KF$method <- "5-fold CV"

rf_result <- rbind(rf_params_HO, rf_params_KF)

for(i in 1:24){
  rf_result$param_idx[i] <- paste0("param", i)
}

rf_result
```

* 해석: Hold-Out에 비해 5-fold CV를 이용하여 튜닝한 결과가 더 좋은 것을 확인할 수 있다. Hold-out의 경우 데이터셋의 크기가 커야 그나마 좋은 성능을 내는 것으로 알고 있는데, 우리의 데이터셋은 row 수가 많지 않아 좋은 성능을 기대할 수 없었을 것이다. 또한 한번 split을 하면 validation set이 고정되어 있는 hold-out과는 달리 k-fold CV는 데이터셋을 k개의 그룹으로 나눈 후 각 그룹이 한번씩 validation set이 되기 때문에 unseen data에 대한 더 나은 지표를 제공할 수 있다. 
```{r}
rf_result %>% ggplot() +
  geom_bar(aes(x = reorder(param_idx, -RMSE), y = RMSE, fill = method, color = method), 
           stat = "identity",  alpha = 0.1, cex = 0.2) +
  geom_text(aes(x = reorder(param_idx, -RMSE), y = RMSE/2, label = round(RMSE, 2), color = method)) +
  coord_flip() +
  scale_fill_manual(values = c("Hold-out" = "#6AA2CD", "5-fold CV" = "#B43C8A")) +
  scale_color_manual(values = c("Hold-out" = "#6AA2CD", "5-fold CV" = "#B43C8A")) +
  theme_set(theme_light(base_family='NanumGothic')) +
  ggtitle("Hold-out vs 5-fold CV 비교") +
  xlab("파라미터 조합") +
  ylab("RMSE")
```

## 문제 13. 랜덤포레스트에서 importance 계산이 어떻게 되는가?
* 각각의 bootstrap sample에서 OOB(out of bag) samples를 구할 수 있는데, 이 때 OOB samples의 경우 model building에 사용되지 않으므로 validation set과 같이 이용될 수 있다.
* 따라서, OOB samples를 모델에 넣어주고, mse(error) 값을 구해준다.
* 그 다음, OOB sample에서 특정 변수에 대한 permutation을 시행한 후 이를 모델에 넣어주어 mse(error)값을 구한다.
* OOB samples permutation 전후의 error 값에 대한 차이를 구한다.
* 따라서, importance는 해당 변수가 랜덤으로 분포되었을 때, 어느 정도 성능이 떨어지는지를 통해 나타난다.

## 문제 14. 가장 좋게 나온 하이퍼파라미터 조합으로 학습
* 가장 좋게 나온 하이퍼파라미터 조합에 대하여 전체 train에 대하여 학습
```{r}
rf_best_param <- rf_result %>% filter(param_idx == "param24")
rf_best_param
```

```{r}
rf_model <- randomForest(등록차량수~., train, 
                              mtry = rf_best_param$mtry,
                              ntree = rf_best_param$ntree)
```

* importance plot 그리기
```{r include=FALSE}
rf_importance <- data.frame(변수명 = rownames(varImpPlot(rf_model)),
                               IncNodePurity = varImpPlot(rf_model))
```

* 해석: OOB samples의 permutation 후에도 error 값이 크게 차이가 나지 않는다면 해당 변수는 중요도가 떨어지는 것으로 해석할 수 있다. 이 plot을 통해거는 단지내주차면수가 가장 유의미한 중요도를 갖는 것을 확인할 수 있다. 
```{r}
rf_importance %>% ggplot(aes(x = reorder(변수명, IncNodePurity), y = IncNodePurity, fill = IncNodePurity, color = IncNodePurity)) +
  geom_bar(stat = "identity", alpha = 0.5, cex = 0.2) +
  coord_flip() +
  scale_fill_gradient(high = "#B43C8A", low = "#81D8D0", aesthetics = "fill") +
  scale_color_gradient(high = "#B43C8A", low = "#81D8D0", aesthetics = "color") +
  theme_set(theme_light(base_family='NanumGothic')) +
  ggtitle("RandomForest Importance Plot") +
  xlab("변수명") +
  ylab("중요도")
  
```

# Chapter 3. XGBoost

## 문제 1. 범주형 변수에 대한 one-hot encoding
```{r}
onehot <- dummyVars(" ~.", data = train)
train_onehot <- predict(onehot, newdata = train) %>% as.data.frame
```

## 문제 2. XGBoost의 하이퍼파라미터에 대한 설명
* eta: GBM의 학습률에 해당하며, 0에서 1 사이의 값을 갖는다.
* nrounds: 약한 학습기의 개수에 해당한다.
* min_child_weight: 트리에서 추가적으로 가지를 나눌지를 결정하기 위해 필요한 데이터들의 weight의 총합에 해당하며, 이 값이 클수록 분할이 자제되어 과적합 제어 용도로 쓰인다.
* max_depth: 트리의 최대 깊이를 나타낸다. 값이 클수록 특정 피처에 특화되어 조건이 만들어지므로 과적합 가능성이 높아진다.
* subsample: 트리가 커져 과적합이 발생하는 것을 제어하기 위해  데이터 샘플링 비율을 지정한다.
* colsample_bytree: 트리 생성에 필요한 피터를 임의로 샘플링 할 때 이용한다. 피처 개수가 많을 경우 과적합 제어에 이용한다.
* 이외에도 alpha, lambda 값을 통해 과적합을 제어할 수 있으며, scale_pos_weight를 통해 비대칭 클래스로 구성된 데이터 세트의 균형을 유지해 줄 수도 있다. 추가적으로 early stopping 설정을 통해서도 과적합을 방지할 수 있다.

## 문제 3. 랜덤 서치 대상 파라미터 샘플링
```{r}
set.seed(2728)

max_depth <- sample(4:10, 12, replace = TRUE)
min_child_weight <- sample(4:10, 12, replace = TRUE)
subsample <-runif(min = 0.5, max = 1, n = 12)
colsample_bytree <- runif(min = 0.5, max = 1, n = 12)
```

## 문제 4. XGBoost 회귀모델링: 5-fold CV 사용
```{r}
xgb_result <- data.frame(iterations = 1:12, 
                      max_depth = max_depth,
                      min_child_weight = min_child_weight,
                      subsample = subsample,
                      colsample_bytree = colsample_bytree,
                      RMSE = NA)

for(i in 1:12){
  RMSE_tmp <- NULL
  
  for(j in 1:5){
    set.seed(2728)
    valid_idx <- cv[[j]]

    cv_train_set <- xgb.DMatrix(data = as.matrix(train_onehot[-valid_idx, -51]), label = as.matrix(train_onehot[-valid_idx, 51]))
    cv_valid_set <- xgb.DMatrix(data = as.matrix(train_onehot[valid_idx, -51]), label = as.matrix(train_onehot[valid_idx, 51]))
    
    xgb_model <- xgboost(data = cv_train_set,
                         max_depth = max_depth[i], 
                         min_child_weight = min_child_weight[i],
                         subsample = subsample[i],
                         colsample_bytree = colsample_bytree[i],
                         eta = 0.01, nrounds = 1000, early_stopping_rounds = 0.05*1000, print_every_n = 50)
    
    xgb_yhat <- predict(xgb_model, newdata = cv_valid_set)
    RMSE_tmp[j] <- RMSE(xgb_yhat, train_onehot[valid_idx, 51])
  }
  xgb_result$RMSE[i] <- mean(RMSE_tmp)
}
```

## 문제 5. 결과 시각화 및 최고 성능을 내는 하이퍼파라미터 조합 도출
* 결과 시각화
```{r}
for(i in 1:12){
  xgb_result$param_idx[i] <- paste0("param", i)
}
xgb_result
```

* 최고의 성능을 내는 하이퍼파라미터 조합
```{r}
xgb_best_param <- xgb_result %>% filter(RMSE == min(RMSE))
```

* 결과 시각화
```{r}
xgb_result %>% ggplot() +
  geom_bar(aes(x = reorder(param_idx, -RMSE), y = RMSE, fill = RMSE, color = RMSE), 
           stat = "identity",  alpha = 0.5, cex = 0.2) +
  geom_text(aes(x = reorder(param_idx, -RMSE), y = RMSE/2, label = round(RMSE, 2), color = RMSE)) +
  coord_flip() +
  scale_fill_gradient(high = "#B43C8A", low = "#81D8D0", aesthetics = "fill") +
  scale_color_gradient(high = "#B43C8A", low = "#81D8D0", aesthetics = "color") +
  theme_set(theme_light(base_family='NanumGothic')) +
  ggtitle("XGboost 결과") +
  xlab("파라미터 조합") +
  ylab("RMSE")
```

* 그리드서치(Grid Search): 그리드서치에서는 각 하이퍼파라미터 조합이 grid로 설정되고, 이떄의 각 하이퍼파라미터 조합을 이용하여 모델을 학습시킨다. 가능한 모든 하이퍼파라미터의 조합에 대해 계산을 진행하므로 비효율적이다. 또한, 단순히 각 조합을 비교하는 것으로 grid search에서 가장 좋은 성능을 내더라도 최적의 파라미터는 아닐 가능성이 존재한다.

* 랜덤서치(Random Search): 핸덤서치에서는 그리드서치와는 달리 탐색할 하이퍼파라미터의 값들이 범위로 주어지고, 해당 범위에서 하이퍼파라미터 값들이 랜덤으로 선택된다. 

* 랜덤서치가 가지는 장점과 단점: 랜덤서치의 경우 불필요한 탐색 횟수를 줄여 그리드서치에 비해 효율적이고, 시간도 적게 걸린다. 또한, 범위 내에서 랜덤으로 파라미터를 탐색하기 때문에 최적의 파라미터를 찾을 가능성이 더 높다. 그러나, 하이퍼파라미터 범위가 너무 넓을 경우 일반화된 결과를 기대하기 어려우며, 범위 내에서 랜덤하게 하이퍼파라미터를 뽑아내므로 시드 고정을 하지 않으면 결과가 매번 달라지게 된다. 또한, 그리드 서치와 같이 여전히 최적화 파라미터를 찾지 못할 가능성이 존재한다.

# Chapter 4. 비교

## 문제 1. test set 불러온 후 train set과 동일하게 전처리
```{r}
test <- fread("test.csv")

test <- test %>% rename("지하철개수" = "도보 10분거리 내 지하철역 수(환승노선 수 반영)",
                 "버스개수" = "도보 10분거리 내 버스정류장 수")

test_na <- which(test$임대료 == "" | test$임대료 == "-")
test$임대료[test_na] <- NA

test_na <- which(test$임대보증금 == "" | test$임대보증금 == "-")
test$임대보증금[test_na] <- NA

test$임대료 <- test$임대료 %>% as.numeric
test$임대보증금 <- test$임대보증금 %>% as.numeric

test <- test %>% 
  mutate_if(is.integer, as.numeric) %>% 
  mutate_if(is.character, as.factor)

test <- test %>% as.data.frame

for(i in 1:ncol(test)){
  if(is.numeric(test[,i]) == FALSE){
    next
  } else {
    test[,i] <- replace(test[,i], is.na(test[,i]), mean(test[,i], na.rm = TRUE))
  }
}

test <- test %>% as.data.table

test$임대료[which(test$공급유형 == "장기전세" & test$임대료 != 0)] <- 0

test <- test %>% mutate(면적당임대료 = 임대료 / 전용면적, 면적당임대보증금 = 임대보증금 / 전용면적)

test <- test %>% select(-c(임대료, 임대보증금, 단지코드))
```

## 문제 2. RandomForest
```{r}
set.seed(2728)
rf_model <- randomForest(등록차량수~., train, 
                              mtry = rf_best_param$mtry,
                              ntree = rf_best_param$ntree)
rf_yhat <- predict(rf_model, test)
rf_RMSE <- RMSE(rf_yhat, test$등록차량수)
```


## 문제 3. XGBoost
* XGBoost 모델링을 위해 test set에 대한 one-hot-encoding 시행
```{r}
onehot <- dummyVars(" ~.", data = test)
test_onehot <- predict(onehot, newdata = test) %>% as.data.frame
```

```{r}
xgb_best_param
```
```{r}
set.seed(2728)
xgb_train <- xgb.DMatrix(data = as.matrix(train_onehot[, -51]), label = as.matrix(train_onehot[, 51]))
xgb_test <- xgb.DMatrix(data = as.matrix(test_onehot[, -51]), label = as.matrix(test_onehot[, 51]))

xgb_model <- xgboost(data = xgb_train,
                     max_depth = xgb_best_param$max_depth,
                     min_child_weight = xgb_best_param$min_child_weight,
                     subsample = xgb_best_param$subsample,
                     colsample_bytree = xgb_best_param$colsample_bytree,
                     eta = 0.01, nrounds = 1000, early_stopping_rounds = 0.05*1000, print_every_n = 50)

xgb_yhat <- predict(xgb_model, newdata = xgb_test)
xgb_RMSE <- RMSE(xgb_yhat, test_onehot[,51])
```


## 문제 4. 2개의 모델링 결과 시각화 및 해석
* 랜덤포레스트에 비해 XGBoost가 RMSE값이 더 작아 더 좋은 성능을 보임을 확인할 수 있다. 그리드서치를 이용하여 하이퍼파라미터 튜닝을 진행한 랜덤포레스트와는 다르게 XGBoost의 경우 랜덤서치를 이용하여 하이퍼파라미터 튜닝을 진행했기 때문에 최적의 파라미터에 더 가까웠을 가능성이 있겠다.
```{r}
model_result <- data.frame(model = c("XGBoost", "RandomForest"), RMSE = c(xgb_RMSE, rf_RMSE))

model_result %>% ggplot(aes(x = model, y = RMSE, fill = model, color = model)) +
  geom_bar(aes(x = model, y = RMSE, fill = model, color = model), stat = "identity", alpha = 0.4, cex = 0.3) +
  geom_text(aes(x = model, y = RMSE/2, label = round(RMSE, 4), color = model)) +
  coord_flip() +
  scale_fill_manual(values = c("RandomForest" = "#6AA2CD", "XGBoost" = "#B43C8A")) +
  scale_color_manual(values = c("RandomForest" = "#6AA2CD", "XGBoost" = "#B43C8A")) +
  theme_set(theme_light(base_family='NanumGothic')) +
  ggtitle("모델 결과 비교") +
  xlab("모델") +
  ylab("RMSE")
```



 